# Understanding-Human-Activities-Using-3D-sensors

##About
Human Activity Recognition (HAR) is the process of identifying the action of a single person or the activity of multiple persons. Human Activity Recognition has been leveraged for wide number of computer vision applications. It has attracted a lot of researchers as well as industries in recent times. Some applications in the field of real world range from healthcare to personal fitness, human computer interaction, video surveillance, gaming, sports analysis, military applications etc.

We propose the use of Deep Recurrent Neural Networks (DRNN) to for vision based Human Activity recognition using 3D sensors. The methods that can be used to make 3D model of our subject are Time of Flight (ToF), stereo triangulation, structured light etc. Our Kinect which is based on structured light will extract the 3D skeleton data. This 3D data is used by the trained Deep Recurrent Neural Network (DRNN) to get a recognized activity.

##Dataset

link1: https://github.com/shahroudy/NTURGB-D

link2: https://github.com/ECHO960/PKU-MMD

Skeleton Modality is used

##Model

1. Deep Recurrent Neural Network (DRNN)
2. Temporal Convolutional Network (TCN)

![This is RNN model](https://github.com/psygorkhali/Understanding-Human-Activities-Using-3D-sensors/blob/master/images/RNN%20model.png)

##Model
Using 3DCNN
RGB Modality is used
