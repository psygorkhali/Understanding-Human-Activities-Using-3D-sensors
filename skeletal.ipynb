{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton based classification\n",
    "## Our model consists of \n",
    "### Two bidirectional Gated Recurrent Unit layer with batch normalization and dropout\n",
    "### One fully connected hidden layer with sigmoid activation\n",
    "### Hidden layer with softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilra\\Anaconda3\\envs\\skeleton\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, GRU, Bidirectional, BatchNormalization, Dropout, CuDNNGRU\n",
    "from keras.optimizers import RMSprop\n",
    "def loaddataset(batch):\n",
    "    #declare the 3D dimension size for the training dataset\n",
    "    train_data = np.zeros((len(batch),300,120),dtype=np.float32)\n",
    "    target_data = np.zeros((len(batch),60), dtype=np.float32)\n",
    "    for sample,actionfile in enumerate(batch):\n",
    "    \n",
    "        #enumerate(os.listdir(\"E:/nturgbd_skeletons/traindata\")):\n",
    "        file = open(\"E:/nturgbd_skeletons/traindata/\" + actionfile,\"r\")\n",
    "        #recognizing actions\n",
    "        action = int(actionfile[18:20])\n",
    "        if (action == 1):\n",
    "            target_data[sample][0] = float(1)\n",
    "        elif (action == 2):\n",
    "            target_data[sample][1] = float(1)\n",
    "        elif (action == 3):\n",
    "            target_data[sample][2] = float(1)\n",
    "        elif (action == 4):\n",
    "            target_data[sample][3] = float(1)\n",
    "        elif (action == 5):\n",
    "            target_data[sample][4] = float(1)\n",
    "        elif (action == 6):\n",
    "            target_data[sample][5] = float(1)\n",
    "        elif (action == 7):\n",
    "            target_data[sample][6] = float(1)\n",
    "        elif (action == 8):\n",
    "            target_data[sample][7] = float(1)\n",
    "        elif (action == 9):\n",
    "            target_data[sample][8] = float(1)\n",
    "        elif (action == 10):\n",
    "            target_data[sample][9] = float(1)\n",
    "        elif (action == 11):\n",
    "            target_data[sample][10] = float(1)\n",
    "        elif (action == 12):\n",
    "            target_data[sample][11] = float(1)\n",
    "        elif (action == 13):\n",
    "            target_data[sample][12] = float(1)\n",
    "        elif (action == 14):\n",
    "            target_data[sample][13] = float(1)\n",
    "        elif (action == 15):\n",
    "            target_data[sample][14] = float(1)\n",
    "        elif (action == 16):\n",
    "            target_data[sample][15] = float(1)\n",
    "        elif (action == 17):\n",
    "            target_data[sample][16] = float(1)\n",
    "        elif (action == 18):\n",
    "            target_data[sample][17] = float(1)\n",
    "        elif (action == 19):\n",
    "            target_data[sample][18] = float(1)\n",
    "        elif (action == 20):\n",
    "            target_data[sample][19] = float(1)\n",
    "        elif (action == 21):\n",
    "            target_data[sample][20] = float(1)\n",
    "        elif (action == 22):\n",
    "            target_data[sample][21] = float(1)\n",
    "        elif (action == 23):\n",
    "            target_data[sample][22] = float(1)\n",
    "        elif (action == 24):\n",
    "            target_data[sample][23] = float(1)\n",
    "        elif (action == 25):\n",
    "            target_data[sample][24] = float(1)\n",
    "        elif (action == 26):\n",
    "            target_data[sample][25] = float(1)\n",
    "        elif (action == 27):\n",
    "            target_data[sample][26] = float(1)\n",
    "        elif (action == 28):\n",
    "            target_data[sample][27] = float(1)\n",
    "        elif (action == 29):\n",
    "            target_data[sample][28] = float(1)\n",
    "        elif (action == 30):\n",
    "            target_data[sample][29] = float(1)\n",
    "        elif (action == 31):\n",
    "            target_data[sample][30] = float(1)\n",
    "        elif (action == 32):\n",
    "            target_data[sample][31] = float(1)\n",
    "        elif (action == 33):\n",
    "            target_data[sample][32] = float(1)\n",
    "        elif (action == 34):\n",
    "            target_data[sample][33] = float(1)\n",
    "        elif (action == 35):\n",
    "            target_data[sample][34] = float(1)\n",
    "        elif (action == 36):\n",
    "            target_data[sample][35] = float(1)\n",
    "        elif (action == 37):\n",
    "            target_data[sample][36] = float(1)\n",
    "        elif (action == 38):\n",
    "            target_data[sample][37] = float(1)\n",
    "        elif (action == 39):\n",
    "            target_data[sample][38] = float(1)\n",
    "        elif (action == 40):\n",
    "            target_data[sample][39] = float(1)\n",
    "        elif (action == 41):\n",
    "            target_data[sample][40] = float(1)\n",
    "        elif (action == 42):\n",
    "            target_data[sample][41] = float(1)\n",
    "        elif (action == 43):\n",
    "            target_data[sample][42] = float(1)\n",
    "        elif (action == 44):\n",
    "            target_data[sample][43] = float(1)\n",
    "        elif (action == 45):\n",
    "            target_data[sample][44] = float(1)\n",
    "        elif (action == 46):\n",
    "            target_data[sample][45] = float(1)\n",
    "        elif (action == 47):\n",
    "            target_data[sample][46] = float(1)\n",
    "        elif (action == 48):\n",
    "            target_data[sample][47] = float(1)\n",
    "        elif (action == 49):\n",
    "            target_data[sample][48] = float(1)\n",
    "        elif (action == 50):\n",
    "            target_data[sample][49] = float(1)\n",
    "        elif (action == 51):\n",
    "            target_data[sample][50] = float(1)\n",
    "        elif (action == 52):\n",
    "            target_data[sample][51] = float(1)\n",
    "        elif (action == 53):\n",
    "            target_data[sample][52] = float(1)\n",
    "        elif (action == 54):\n",
    "            target_data[sample][53] = float(1)\n",
    "        elif (action == 55):\n",
    "            target_data[sample][54] = float(1)\n",
    "        elif (action == 56):\n",
    "            target_data[sample][55] = float(1)\n",
    "        elif (action == 57):\n",
    "            target_data[sample][56] = float(1)\n",
    "        elif (action == 58):\n",
    "            target_data[sample][57] = float(1)\n",
    "        elif (action == 59):\n",
    "            target_data[sample][58] = float(1)\n",
    "        elif (action == 60):\n",
    "            target_data[sample][59] = float(1)\n",
    "        \n",
    "            \n",
    "        #read number of frame/ here frame number is the timesteps\n",
    "        framecount = int(file.readline())\n",
    "        #print(\"file no: \"+ actionfile)\n",
    "        for framenum in range(framecount):\n",
    "            #we'll have total of 20joints with each x,y,z point so total of 20x3=60 feature vector\n",
    "            #each frame has 60 features\n",
    "            #print(\"frame number: \"+str(framenum))\n",
    "            feature = 0;\n",
    "            #read the total skeleton number and ignore it\n",
    "            bodycount = int(file.readline())\n",
    "            for body in range(bodycount):\n",
    "                #read the body info and ignore it\n",
    "                file.readline()\n",
    "                #read joint number and converting the joint number string to integer\n",
    "                jointsnum = int(file.readline())\n",
    "                if (body < 2 ):\n",
    "                    #looping through only 20 joints\n",
    "                    for joint in range(jointsnum-5):\n",
    "\n",
    "                        #getting the x y z coordinate from the files and ignoring other information\n",
    "                        numbers = file.readline().split()\n",
    "                        train_data[sample][framenum][feature] = numbers[0]\n",
    "                        feature+=1\n",
    "                        train_data[sample][framenum][feature] = numbers[1]\n",
    "                        feature+=1\n",
    "                        train_data[sample][framenum][feature] = numbers[2]\n",
    "                        feature+=1\n",
    "                    #ignoring the remaining 5 joints\n",
    "                    for i in range(5):\n",
    "                        file.readline()\n",
    "                else:\n",
    "                    for i in range(25):\n",
    "                        file.readline()\n",
    "\n",
    "    return (train_data, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadvalidationdataset():\n",
    "    #declare the 3D dimension size for the training dataset\n",
    "    train_data = np.zeros((10000,300,120),dtype=np.float32)\n",
    "    target_data = np.zeros((10000,60), dtype=np.float32)\n",
    "    for sample,actionfile in enumerate(os.listdir(\"E:/nturgbd_skeletons/validationdata\")):\n",
    "    \n",
    "        #enumerate(os.listdir(\"E:/nturgbd_skeletons/traindata\")):\n",
    "        file = open(\"E:/nturgbd_skeletons/validationdata/\" + actionfile,\"r\")\n",
    "        #recognizing actions\n",
    "        action = int(actionfile[18:20])\n",
    "        if (action == 1):\n",
    "            target_data[sample][0] = float(1)\n",
    "        elif (action == 2):\n",
    "            target_data[sample][1] = float(1)\n",
    "        elif (action == 3):\n",
    "            target_data[sample][2] = float(1)\n",
    "        elif (action == 4):\n",
    "            target_data[sample][3] = float(1)\n",
    "        elif (action == 5):\n",
    "            target_data[sample][4] = float(1)\n",
    "        elif (action == 6):\n",
    "            target_data[sample][5] = float(1)\n",
    "        elif (action == 7):\n",
    "            target_data[sample][6] = float(1)\n",
    "        elif (action == 8):\n",
    "            target_data[sample][7] = float(1)\n",
    "        elif (action == 9):\n",
    "            target_data[sample][8] = float(1)\n",
    "        elif (action == 10):\n",
    "            target_data[sample][9] = float(1)\n",
    "        elif (action == 11):\n",
    "            target_data[sample][10] = float(1)\n",
    "        elif (action == 12):\n",
    "            target_data[sample][11] = float(1)\n",
    "        elif (action == 13):\n",
    "            target_data[sample][12] = float(1)\n",
    "        elif (action == 14):\n",
    "            target_data[sample][13] = float(1)\n",
    "        elif (action == 15):\n",
    "            target_data[sample][14] = float(1)\n",
    "        elif (action == 16):\n",
    "            target_data[sample][15] = float(1)\n",
    "        elif (action == 17):\n",
    "            target_data[sample][16] = float(1)\n",
    "        elif (action == 18):\n",
    "            target_data[sample][17] = float(1)\n",
    "        elif (action == 19):\n",
    "            target_data[sample][18] = float(1)\n",
    "        elif (action == 20):\n",
    "            target_data[sample][19] = float(1)\n",
    "        elif (action == 21):\n",
    "            target_data[sample][20] = float(1)\n",
    "        elif (action == 22):\n",
    "            target_data[sample][21] = float(1)\n",
    "        elif (action == 23):\n",
    "            target_data[sample][22] = float(1)\n",
    "        elif (action == 24):\n",
    "            target_data[sample][23] = float(1)\n",
    "        elif (action == 25):\n",
    "            target_data[sample][24] = float(1)\n",
    "        elif (action == 26):\n",
    "            target_data[sample][25] = float(1)\n",
    "        elif (action == 27):\n",
    "            target_data[sample][26] = float(1)\n",
    "        elif (action == 28):\n",
    "            target_data[sample][27] = float(1)\n",
    "        elif (action == 29):\n",
    "            target_data[sample][28] = float(1)\n",
    "        elif (action == 30):\n",
    "            target_data[sample][29] = float(1)\n",
    "        elif (action == 31):\n",
    "            target_data[sample][30] = float(1)\n",
    "        elif (action == 32):\n",
    "            target_data[sample][31] = float(1)\n",
    "        elif (action == 33):\n",
    "            target_data[sample][32] = float(1)\n",
    "        elif (action == 34):\n",
    "            target_data[sample][33] = float(1)\n",
    "        elif (action == 35):\n",
    "            target_data[sample][34] = float(1)\n",
    "        elif (action == 36):\n",
    "            target_data[sample][35] = float(1)\n",
    "        elif (action == 37):\n",
    "            target_data[sample][36] = float(1)\n",
    "        elif (action == 38):\n",
    "            target_data[sample][37] = float(1)\n",
    "        elif (action == 39):\n",
    "            target_data[sample][38] = float(1)\n",
    "        elif (action == 40):\n",
    "            target_data[sample][39] = float(1)\n",
    "        elif (action == 41):\n",
    "            target_data[sample][40] = float(1)\n",
    "        elif (action == 42):\n",
    "            target_data[sample][41] = float(1)\n",
    "        elif (action == 43):\n",
    "            target_data[sample][42] = float(1)\n",
    "        elif (action == 44):\n",
    "            target_data[sample][43] = float(1)\n",
    "        elif (action == 45):\n",
    "            target_data[sample][44] = float(1)\n",
    "        elif (action == 46):\n",
    "            target_data[sample][45] = float(1)\n",
    "        elif (action == 47):\n",
    "            target_data[sample][46] = float(1)\n",
    "        elif (action == 48):\n",
    "            target_data[sample][47] = float(1)\n",
    "        elif (action == 49):\n",
    "            target_data[sample][48] = float(1)\n",
    "        elif (action == 50):\n",
    "            target_data[sample][49] = float(1)\n",
    "        elif (action == 51):\n",
    "            target_data[sample][50] = float(1)\n",
    "        elif (action == 52):\n",
    "            target_data[sample][51] = float(1)\n",
    "        elif (action == 53):\n",
    "            target_data[sample][52] = float(1)\n",
    "        elif (action == 54):\n",
    "            target_data[sample][53] = float(1)\n",
    "        elif (action == 55):\n",
    "            target_data[sample][54] = float(1)\n",
    "        elif (action == 56):\n",
    "            target_data[sample][55] = float(1)\n",
    "        elif (action == 57):\n",
    "            target_data[sample][56] = float(1)\n",
    "        elif (action == 58):\n",
    "            target_data[sample][57] = float(1)\n",
    "        elif (action == 59):\n",
    "            target_data[sample][58] = float(1)\n",
    "        elif (action == 60):\n",
    "            target_data[sample][59] = float(1)\n",
    "        \n",
    "            \n",
    "        #read number of frame/ here frame number is the timesteps\n",
    "        framecount = int(file.readline())\n",
    "        #print(\"file no: \"+ actionfile)\n",
    "        for framenum in range(framecount):\n",
    "            #we'll have total of 20joints with each x,y,z point so total of 20x3=60 feature vector\n",
    "            #each frame has 60 features\n",
    "            #print(\"frame number: \"+str(framenum))\n",
    "            feature = 0;\n",
    "            #read the total skeleton number and ignore it\n",
    "            bodycount = int(file.readline())\n",
    "            for body in range(bodycount):\n",
    "                #read the body info and ignore it\n",
    "                file.readline()\n",
    "                #read joint number and converting the joint number string to integer\n",
    "                jointsnum = int(file.readline())\n",
    "                if (body < 2 ):\n",
    "                    #looping through only 20 joints\n",
    "                    for joint in range(jointsnum-5):\n",
    "\n",
    "                        #getting the x y z coordinate from the files and ignoring other information\n",
    "                        numbers = file.readline().split()\n",
    "                        train_data[sample][framenum][feature] = numbers[0]\n",
    "                        feature+=1\n",
    "                        train_data[sample][framenum][feature] = numbers[1]\n",
    "                        feature+=1\n",
    "                        train_data[sample][framenum][feature] = numbers[2]\n",
    "                        feature+=1\n",
    "                    #ignoring the remaining 5 joints\n",
    "                    for i in range(5):\n",
    "                        file.readline()\n",
    "                else:\n",
    "                    for i in range(25):\n",
    "                        file.readline()\n",
    "\n",
    "    return (train_data, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all the skeleton files in traindata directory\n",
    "file_list = os.listdir(\"E:/nturgbd_skeletons/traindata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(batch_size = 500):\n",
    "    batch = np.random.choice(file_list, batch_size, replace=False)\n",
    "    print(\"loading batch dataset\")\n",
    "    return loaddataset(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#define first two bidirectional lstm/gru layer with around 300 neurons\n",
    "model.add(Bidirectional(CuDNNGRU(300, return_sequences=True), input_shape=(300, 120)))\n",
    "model.add(Bidirectional(CuDNNGRU(300)))\n",
    "model.add(BatchNormalization(momentum=0.0, epsilon=0.00001))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "#define a fully connected hidden layer with about 300 neurons\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('sigmoid'))\n",
    "#define a output layer with 3 neurons\n",
    "model.add(Dense(60))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01, decay=0.9),  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation dataset...\n",
      "dataset validation loaded..\n"
     ]
    }
   ],
   "source": [
    "print(\"loading validation dataset...\")\n",
    "vtrain, vtarget = loadvalidationdataset()\n",
    "print(\"dataset validation loaded..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading batch dataset\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ab6e061eb62b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# history = model.fit(vtrain, vtarget, batch_size=20, epochs=10,callbacks = [tensorboard], verbose=2, validation_split=0.05, shuffle=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# for epoch in range(5):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#     for batch in range(4):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\skeleton\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\skeleton\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\skeleton\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\skeleton\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2192\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2193\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2194\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2196\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\skeleton\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m                 \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\skeleton\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\skeleton\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m_data_generator_task\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    656\u001b[0m                             \u001b[1;31m# => Serialize calls to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m                             \u001b[1;31m# infinite iterator/generator's next() function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                             \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not an iterator"
     ]
    }
   ],
   "source": [
    "# from keras.callbacks import TensorBoard\n",
    "# # for epoch in range(8):\n",
    "# #     train_data, target_data = gen()\n",
    "# tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\n",
    "# history = model.fit(vtrain, vtarget, batch_size=20, epochs=10,callbacks = [tensorboard], verbose=2, validation_split=0.05, shuffle=True)\n",
    "model.fit_generator(generator = gen(), steps_per_epoch=4, epochs=5, verbose=2, validation_data=(vtrain, vtarget),shuffle=True)\n",
    "# for epoch in range(5):\n",
    "#     for batch in range(4):\n",
    "#         x,y = gen()\n",
    "#         model.train_on_batch(x, y)\n",
    "#         model.test_on_batch(vtrain, vtarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
